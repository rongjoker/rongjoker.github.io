---
layout: post
title: 45讲Mysql(一):1-11
---


### 第一讲 一条SQL如何执行

MySQL 可以分为 Server 层和存储引擎层两部分。Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。而存储引擎层负责数据的存储和提取。<br>
1. 连接器(建立连接、获取权限、维护和管理连接)
2. 查询缓存(版本8取消了此功能)
3. 分析器(词法分析、语法分析、提示语法错误)
4. 优化器(通过分析器，明白你要干啥后，数据库就要针对你的需求想一个最优的解决方案，也就是执行计划，这个最优方案选择的操作，这个就是优化器要做的事情了。比如多个索引选择用哪个索引，多个表连接时选择什么连接顺序。优化器会改写sql，包括join的连接顺序，匹配索引，找到最优sql策略)
5. 执行器
   <br>
   [![haeVkF.md.png](https://z3.ax1x.com/2021/08/31/haeVkF.md.png)](https://imgtu.com/i/haeVkF)
   <br>
问题:如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？

答案: 《高性能mysql》里提到解析器和预处理器。 解析器处理语法和解析查询, 生成一课对应的解析树。 预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器。错误发生在在分析器处理阶段


### 第二讲 日志系统：一条SQL更新语句是如何执行的

WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。注意，日志也是写入硬盘，只不过顺序写入速度很快。也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，Redis的AOF(Append Only File)日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。 InnoDB正因为有了 redo log(重做日志)，才有了 crash-safe 的能力（即使mysql服务宕机，也不会丢失数据的能力）。**redo log用于 crash时的数据丢失恢复，binlog用于恢复到一个之前的某个时间点的恢复。**
<br>
binlog只有在事务提交的时候才会写入,redolog在事务开启之后就会写入了,当数据库发生异常,事务还未提交的时候,这时候这个事务里的更新全部都会丢失,如果没有redolog写入更新的话,binlog里是不会有未提交的事务的数据的.
<br>binlog是追加写，crash时不能判定binlog中哪些内容是已经写入到磁盘，哪些还没被写入。而redolog是循环写，从check point到write pos间的内容都是未写入到磁盘的。

<br>
更新的过程
1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。注意，是页，而不是一条数据。操作系统层面读取磁盘的最小单位就是页，内存页、cache页和磁盘页都是一样大小，一般是4B。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。
可见，更新是两阶段提交。

数据恢复。找到一个备份点。从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。在数据恢复和扩容时不会出现数据丢失或者主从数据库不一致。<br>
redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。
<br>
第一、redo log是一个特定的区域，写入操作是顺序写，非常快，而将数据刷新到磁盘是随机io，比较慢，所以要先写入redo log。 第二、update操作是要把数据查询到buffer_pool(非唯一索引可以不用先查询，可以先把要改动的操作存在change_buffer中，然后等空闲的时候或者其他操作再merge)，查询出来之后，这一页数据就在buffer_pool中，MySQL会先把buffer_pool里面的这页数据更新到最新同时写redo log，然后就更新结束了，此时在bufferpool里面的页就是脏页，后续会刷新到磁盘中。


### 第三讲 事务隔离：为什么你改了我还看不见？

可重复读：事务在执行期间看到的数据前后必须是一致的。可重复读场景，其实就是事务开始以后不希望被打扰.事务启动时的视图可以认为是静态的，不受其他事务更新的影响。<br>
实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。这一点被seata所借鉴。<br>
长事务的坏处:长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。<br>
避免长事务？ 长事务的来源应该是一次获取大量的数据，查询方式不合理（全表扫描）。 那么解决问题的方式是： 1）利用索引 2）分批获取数据.
创建视图快照会以select执行开始的时间点为快照点,而不是以begin为起始点

[![hsW9vn.md.png](https://z3.ax1x.com/2021/09/02/hsW9vn.md.png)](https://imgtu.com/i/hsW9vn)

V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。V3是因为提交了事务，快照更新为当前读。

### 第四、五讲 深入浅出索引
主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。<br>
b+树的容量:以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。<br>
回表：<br>
逐个找到符合条件的叶子节点，再根据其存储的主键值逐一回表查询。并不是直接一次性查出符合条件的主键值，然后一次性回表查询。回表次数比想象得要多得多。
<br>
MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
```

CREATE TABLE `geek` (
  `a` int(11) NOT NULL,
  `b` int(11) NOT NULL,
  `c` int(11) NOT NULL,
  `d` int(11) NOT NULL,
  PRIMARY KEY (`a`,`b`),
  KEY `c` (`c`),
  KEY `ca` (`c`,`a`),
  KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;

```
对于二级索引C，会默认和主键做联合索引。所以索引c的排序为cab，索引cb的排序顺序为cba。所以，结论是 ca 可以去掉，cb 需要保留。
<br>
为什么要重建索引。我们文章里面有提到，索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。


### 第六讲 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？
元数据锁(MDL)是server层的锁，表级锁，主要用于隔离DML（Data Manipulation Language，数据操纵语言，如select）和DDL（Data Definition Language，数据定义语言，如改表头新增一列）操作之间的干扰。每执行一条DML、DDL语句时都会申请MDL锁，DML操作需要MDL读锁，DDL操作需要MDL写锁（MDL加锁过程是系统自动控制，无法直接干预，读读共享，读写互斥，写写互斥）<br>
申请MDL锁的操作会形成一个队列，队列中写锁获取优先级高于读锁.<br>
如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。<br>
如何安全地给小表加字段？
1. 首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。
2. 对于热点表,比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。
<br>
online ddl<br>
3. 拿MDL写锁
4. 降级成MDL读锁
5. 真正做DDL
6. 升级成MDL写锁
7. 释放MDL锁
<br>
问题:备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？
答案:主库上的一个小表做了一个 DDL, 同步给slave ,由于这个时候有了先前的 single-transaction,所以slave 就会出现 该表的 锁等待, 并且slave 出现延迟

### 第七讲 行锁功过：怎么减少行锁对性能的影响？

两阶段锁协议:在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。<br>
**innodb行级锁是通过锁索引记录实现的**。如`update t set t.name='abc' where t.name='cde'`; name字段无索引，会扫描表。<br>
死锁:当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。即循环依赖或者循环等待。<br>
死锁解决:
1. 等待超时
2. 死锁检测

实用方案:<br>
通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。相当于子账户的概念，原理上就是分段汇总，Java原子类LongAdder也使用了这个原理。影子账户。

问题:
如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：第一种，直接执行 delete from T limit 10000;第二种，在一个连接中循环执行 20 次 delete from T limit 500;第三种，在 20 个连接中同时执行 delete from T limit 500。
答案:第二种最好。第一种人为制造大事务，第三种人为制造锁冲突。




### 第八讲 事务到底是隔离的还是不隔离的？
<br>

[![hafCm4.md.png](https://z3.ax1x.com/2021/08/31/hafCm4.md.png)](https://imgtu.com/i/hafCm4)
<br>
在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。事务 B 在更新了行之后查询 ; 事务 A 在一个只读事务中查询，并且时间顺序上是在事务 B 的查询之后。 事务 B 查到的 k 的值是 3，而事务 A 查到的 k 的值是 1，
A强制开启了事务(start transaction with consistent snapshot);否则A的k也是3
<br>
InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。
<br>
多版本的实现:<br>
InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。
<br>
因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。<br>
一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
1. 版本未提交，不可见；
2. 版本已提交，但是是在视图创建后提交的，不可见；
3. 版本已提交，而且是在视图创建前提交的，可见。
更新和读有一个很大的区别。
**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**
事务隔离的本质实现: 两阶段锁协议+MVCC
<br>
   [![haoFWn.md.png](https://z3.ax1x.com/2021/08/31/haoFWn.md.png)](https://imgtu.com/i/haoFWn)

```
当前库存：num=200
假如多线程并发：
AB同时开启事务，A先请求到行锁，
A：
start transaction;
select num from t where num>0;先查询当前库存值（num>0）
update t set num=num-200; 库存减量

B：
start transaction;
select num from t where num>0;先查询当前库存值（num>0）
update t set num=num-200; 库存减量
----结果---
A：查询到num=200,做了库存减量成了0
B：事务启动后，查询到也是200，等 A 释放了行锁，B进行update，直接变成 -200
但是 B 查询时，时有库存的，因此才减库存，结果变成负的。

```
比较简单的做法是update语句的where 部分加一个条件： where nun >=200 . 然后在程序里判断这个update 语句的affected_rows, 如果等于1 那就是符合预期； 如果等于0，那表示库存不够减了，业务要处理一下去，比如提示“库存不足” .并发场景下，update 的时候能加上条件要尽量加上条件.

### 第九讲 普通索引和唯一索引，应该怎么选择？
普通索引不仅仅是查询时有区别，还在于普通索引可以使用change buffer，可以提高性能.<br>
更新语句差异： 普通索引 将数据页从磁盘读入内存，更新数据页。 唯一索引 将数据页从磁盘读入内存，判断是否唯一，再更新数据页。
执行上的区别： 普通索引的等值查询，会继续遍历到第一个不相等的值才会结束，而唯一索引等值查询，命中则结束（性能差距微乎其微）
性能差距很小。InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。
除非重复的非常多，跨了多个页。

```
有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。
```

### 第十讲 MySQL为什么有时候会选错索引
MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。



### 第十一讲 怎么给字符串字段加索引？
创建前缀索引
```
alter table SUser add index index2(email(6));
```
执行查询:
```
select id,name,email from SUser where email='zhangssxyz@xxx.com';
```
可以通过查询确定用几位数的索引比较好:
```
mysql> select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```
前缀索引可以减小索引的大小，占用空间小，数据量很大的情况下深度比较浅。不过前缀索引无法利用到覆盖索引的优势，还是要回表。
**身份证建立索引**<br>
1. 倒序存储
```
mysql> select field_list from t where id_card = reverse('input_id_card_string');
```
2. 使用 hash 字段
```
mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);

mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
```
问题:如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。

答案:由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是 @gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。<br>
而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。

> 思考题的学号比较特殊，15位数字+固定后缀“@gmail.com” 这种特殊的情况，可以把学号使用bigint存储,占4个字节，比前缀索引空间占用要小。跟hash索引比， 也有区间查询的优势

-- 附录
> MDL（metadata lock）
> DDL（data definition Language）
> DML（da ta Manipulation language）

