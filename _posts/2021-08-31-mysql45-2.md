---
layout: post
title: 45讲Mysql(二):12-
---


### 第十二讲 为什么我的MySQL会“抖”一下？
利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。由此也带来了内存脏页的问题。
当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。<br>
**平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）**<br>
flush出现的场景:<br>
1. InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写
2. 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘
3. MySQL 认为系统“空闲”的时候
4. MySQL 正常关闭的情况

问题:
一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？
回答:
因为 checkpoint 一直要往前推，这个操作就会触发 merge 操作，然后又进一步地触发刷脏页操作


### 第十三讲 为什么表数据删掉一半，表文件大小不变？
delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。新增(引发裂变)、修改(删除一个值添加另外一个值)都可能引发`空洞` 。<br>
**重建表** alter table A engine=InnoDB 重建表空间，释放空洞的空间，缩容。由于日志文件记录和重放操作这个功能的存在，故支持Online DDL

问题：什么时候使用 alter table t engine=InnoDB 会让一个表占用的空间反而变大。
回答：
1. 这个表，本身就已经没有空洞的了，比如说刚刚做过一次重建表操作。在 DDL 期间，如果刚好有外部的 DML 在执行，这期间可能会引入一些新的空洞。
2. InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。

### 第十四讲 count(*)这么慢，我该怎么办？
TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。<br>
可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。<br>
对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
<br>
按照执行效率:count(字段)<count(主键 id)<count(1)≈count(*)

### 第十五讲 答疑文章（一）：日志和索引相关问题
问:redo log 和 binlog 是怎么关联起来的?<br>
答:它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。
问:当 MySQL 去更新一行，但是要修改的值跟原来的值是相同的，这时候 MySQL 会真的去执行一次修改吗？还是看到值相同就直接返回呢？
答:InnoDB 认真执行了“把这个值修改成 (1,2)"这个操作，该加锁的加锁，该更新的更新。


### 第十六讲  “order by”是怎么工作的？

sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。
<br>
MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。<br>
问题:
假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 `select * from t where city in ('杭州'," 苏州 ") order by name limit 100;` 是否需要重新排序
回答:
需要。原因是索引顺序城市、名称 与 单独按name排序的顺序不一致
解决方案:
执行 select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。执行 select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组 B。现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。

### 第十八讲  为什么这些SQL语句逻辑相同，性能却差异巨大？
1. 由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。
2.隐式类型转换
`mysql> select * from tradelog where tradeid=110717;`中tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。

### 第十九讲 为什么我只查一行的语句，也执行这么慢？
第一类：查询长时间不返回，如`第一类：查询长时间不返回`，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。
1. `Waiting for table metadata lock`，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。
2. `Waiting for table flush` 出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。
第二类：查询慢 查询的字段没有加索引

### 第二十讲  幻读是什么，幻读有什么问题？(关键)
对于非索引字段进行update或select .. for update操作，代价极高。所有记录上锁，以及所有间隔的锁。 对于索引字段进行上述操作，代价一般。只有索引字段本身和附近的间隔会被加锁。update、delete语句用不上索引是很恐怖的<br>
```

SELECT * FROM t where c>=15 and c<=20 for update; 会加如下锁：
next-key lock:(10, 15], (15, 20]
gap lock:(20, 25)

SELECT * FROM t where c>=15 and c<=20 order by c desc for update; 会加如下锁：
next-key lock:(5, 10], (10, 15], (15, 20]
gap lock:(20, 25)

session C 被锁住的原因就是根据索引 c 逆序排序后多出的 next-key lock:(5, 10]
```

间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。
<br>
[![hdwsnx.md.png](https://z3.ax1x.com/2021/08/31/hdwsnx.md.png)](https://imgtu.com/i/hdwsnx)
<br>
有间隙的地方就可能有间隙锁。只在二级索引上。
实际上在判断间隙的时候，varchar 和 int 是一样的，排好序以后，相邻两个值之间就有间隙。

```
begin;
select * from t where d=5 for update;
commit;
```
比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。<br>
我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。<br>
间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。锁住了所有的行和所有可能的行，解决幻读的问题。但是间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。


### 第二十一讲 为什么我只改一行的语句，锁这么多？
加锁的原则：
原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
原则 2：查找过程中访问到的对象才会加锁。
优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

### 第二十二讲 MySQL有哪些“饮鸩止渴”提高性能的方法？
使用truncate table删除了指定表中的所有行，但表的结构及其列，约束，索引等保持不变，而新行标识所用的计数值重置为该列的初始值
<br>
长事务的影响:<br>
1. 如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；
2. 当然读的事务也有问题，就是会导致 undo log 不能被回收，导致回滚段空间膨胀;
3. 同一个事务，更新之后要尽快提交，不要做没必要的查询，尤其是不要执行需要返回大量数据的查询



### 第三十三讲 我查这么多数据，会不会把数据库内存打爆？
我的主机内存只有 100G，现在要对一个 200G 的大表做全表扫描，会不会把数据库主机的内存用光了？<br>
实际上，服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：
1. 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
2. 重复获取行，直到 net_buffer 写满，调用网络接口发出去。
3. 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
4. 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

<br>可见,占用的 MySQL 内部的内存最大就是 net_buffer_length 这么大。如果你看到 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。<br>
内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。<br>
**InnoDB 管理 Buffer Pool 的 LRU 算法**
<br>
在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。
<br>
1. 将LUR链表分成young和old区域 
2. young区域算法仍然是最新访问过得数据放在head 
3. old区域存放从磁盘读出的数据，根据存放时间判断是否移至young区域 
4. 时间由innodb_old_blocks_time参数控制
5. 扫描过程中，需要新插入的数据页，都被放到 old 区域 ;
<br>防止大表扫描时候Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。
<br>“边读边发”的意思是，算出来的结果才能发.order by，得先排序得到结果，然后才发出去，如果读了数据直接发，那肯定不行，那是错误的结果。所以要排序了以后再发，这时候就需要中间数据结构，sort buffer




### 第三十四讲 到底可不可以使用join？
`select * from t1 straight_join t2 on (t1.a=t2.a);` 如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，straight_join 让 MySQL 使用固定的连接方式执行查询.
有索引采用Simple Nested-Loop Join算法，无索引采用Block Nested-Loop Join，全表扫描.全表扫描会放入join_buffer，join_buffer空间不够则会分段放入，故叫block。
所以你在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样，有的话尽量别用join。<br>
在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

###  第三十五讲 join语句怎么优化？
Multi-Range Read 多范围读(MRR) , 它的作用针对基于辅助/第二索引的查询，减少随机IO，并且将随机IO转化为顺序IO，提高查询效率。具体步骤:
1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
2. 将 read_rnd_buffer 中的 id 进行递增排序；
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。
<br>

   [![hsA2CT.md.jpg](https://z3.ax1x.com/2021/09/02/hsA2CT.md.jpg)](https://imgtu.com/i/hsA2CT)
